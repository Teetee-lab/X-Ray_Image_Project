{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# # This Python 3 environment comes with many helpful analytics libraries installed\n# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# # For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# # Input data files are available in the read-only \"../input/\" directory\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-16T22:30:49.671133Z","iopub.status.idle":"2021-11-16T22:30:49.672002Z","shell.execute_reply.started":"2021-11-16T22:30:49.671666Z","shell.execute_reply":"2021-11-16T22:30:49.671702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#import necessary libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout , BatchNormalization\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report,confusion_matrix\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\nimport cv2\nimport os\nfrom glob import glob\nfrom keras.models import Sequential \nfrom keras.layers import Conv2D, MaxPooling2D, Activation, Dropout, Flatten, Dense\nfrom keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img","metadata":{"execution":{"iopub.status.busy":"2021-11-16T22:30:52.549023Z","iopub.execute_input":"2021-11-16T22:30:52.549381Z","iopub.status.idle":"2021-11-16T22:30:52.565750Z","shell.execute_reply.started":"2021-11-16T22:30:52.549338Z","shell.execute_reply":"2021-11-16T22:30:52.564092Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"#downloading data from folder\ntrain_dir = '/kaggle/input/chest-xray-pneumonia/chest_xray/chest_xray/train'\ntest_dir =  '/kaggle/input/chest-xray-pneumonia/chest_xray/chest_xray/test'\nval_dir = '/kaggle/input/chest-xray-pneumonia/chest_xray/chest_xray/val'","metadata":{"execution":{"iopub.status.busy":"2021-11-16T22:31:49.847602Z","iopub.execute_input":"2021-11-16T22:31:49.848496Z","iopub.status.idle":"2021-11-16T22:31:49.854033Z","shell.execute_reply.started":"2021-11-16T22:31:49.848458Z","shell.execute_reply":"2021-11-16T22:31:49.852737Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"#Define function that will help split our data into X and Y and resize it \ndef picture_separation(folder):\n    \"\"\"\n    source code from:https://medium.com/analytics-vidhya/how-to-load-any-image-dataset-in-python-3bd2fa2cb43d\n    and https://www.kaggle.com/rafetcan/\n    input: folder\n    \"\"\"\n    y = []\n    x = []\n    image_list = []\n\n    for foldername in os.listdir(folder):\n        if not foldername.startswith('.'):\n            if foldername == \"NORMAL\":\n                label = 0\n            elif foldername == \"PNEUMONIA\":\n                label = 1\n            else:\n                label = 2\n                \n            for image_filename in os.listdir(folder + \"/\"+ foldername):\n                img_file = cv2.imread(folder + \"/\" + foldername + '/' + image_filename,0)               \n                if img_file is not None:\n                    img = cv2.resize(img_file,(64,64)) #resize img\n                    img_arr = img_to_array(img) / 255\n                    x.append(img_arr)\n                    y.append(label)\n                    image_list.append(foldername + '/' + image_filename)\n                                        \n    X = np.asarray(x) #create an array of images for X\n    y = np.asarray(y) #create an array of images for y\n    \n    \n\n    return X,y,image_list\n","metadata":{"execution":{"iopub.status.busy":"2021-11-16T23:16:56.036400Z","iopub.execute_input":"2021-11-16T23:16:56.036754Z","iopub.status.idle":"2021-11-16T23:16:56.047796Z","shell.execute_reply.started":"2021-11-16T23:16:56.036707Z","shell.execute_reply":"2021-11-16T23:16:56.046609Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"#put the images in a dataframe \nX_train, y_train, img_train = picture_separation(train_dir)\n\ntrain_df = pd.DataFrame(img_train, columns=[\"images\"])\ntrain_df[\"target\"] = y_train","metadata":{"execution":{"iopub.status.busy":"2021-11-16T22:32:50.417400Z","iopub.execute_input":"2021-11-16T22:32:50.417820Z","iopub.status.idle":"2021-11-16T22:33:42.134473Z","shell.execute_reply.started":"2021-11-16T22:32:50.417780Z","shell.execute_reply":"2021-11-16T22:33:42.133432Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"#checking the shape of the X_train \nX_train.shape","metadata":{"execution":{"iopub.status.busy":"2021-11-16T22:33:48.525352Z","iopub.execute_input":"2021-11-16T22:33:48.525728Z","iopub.status.idle":"2021-11-16T22:33:48.537430Z","shell.execute_reply.started":"2021-11-16T22:33:48.525688Z","shell.execute_reply":"2021-11-16T22:33:48.534970Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"#checking the shape of the y_train \ny_train.shape","metadata":{"execution":{"iopub.status.busy":"2021-11-16T22:33:51.487941Z","iopub.execute_input":"2021-11-16T22:33:51.488220Z","iopub.status.idle":"2021-11-16T22:33:51.495991Z","shell.execute_reply.started":"2021-11-16T22:33:51.488190Z","shell.execute_reply":"2021-11-16T22:33:51.494776Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"#check the first 4 rows of the train dataset\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-16T22:34:01.049098Z","iopub.execute_input":"2021-11-16T22:34:01.049409Z","iopub.status.idle":"2021-11-16T22:34:01.062323Z","shell.execute_reply.started":"2021-11-16T22:34:01.049379Z","shell.execute_reply":"2021-11-16T22:34:01.061076Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"#check the info of the train dataset\ntrain_df.info()","metadata":{"execution":{"iopub.status.busy":"2021-11-16T22:34:05.471543Z","iopub.execute_input":"2021-11-16T22:34:05.472283Z","iopub.status.idle":"2021-11-16T22:34:05.488163Z","shell.execute_reply.started":"2021-11-16T22:34:05.472234Z","shell.execute_reply":"2021-11-16T22:34:05.486122Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"#put the val dataset in a dataframe \nX_val, y_val, img_val = picture_separation(val_dir)\n\nval_df = pd.DataFrame(img_val, columns=[\"images\"])\nval_df[\"target\"] = y_val","metadata":{"execution":{"iopub.status.busy":"2021-11-16T22:34:07.991872Z","iopub.execute_input":"2021-11-16T22:34:07.992746Z","iopub.status.idle":"2021-11-16T22:34:08.160579Z","shell.execute_reply.started":"2021-11-16T22:34:07.992713Z","shell.execute_reply":"2021-11-16T22:34:08.159476Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"X_val.shape","metadata":{"execution":{"iopub.status.busy":"2021-11-16T22:34:10.772440Z","iopub.execute_input":"2021-11-16T22:34:10.778933Z","iopub.status.idle":"2021-11-16T22:34:10.792527Z","shell.execute_reply.started":"2021-11-16T22:34:10.778868Z","shell.execute_reply":"2021-11-16T22:34:10.791502Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"#put the test dataset in a dataframe \nX_test, y_test, img_test = picture_separation(test_dir)\n\ntest_df = pd.DataFrame(img_test, columns=[\"images\"])\ntest_df[\"target\"] = y_test","metadata":{"execution":{"iopub.status.busy":"2021-11-16T22:34:13.020079Z","iopub.execute_input":"2021-11-16T22:34:13.020370Z","iopub.status.idle":"2021-11-16T22:34:18.100392Z","shell.execute_reply.started":"2021-11-16T22:34:13.020340Z","shell.execute_reply":"2021-11-16T22:34:18.099411Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"X_test.shape","metadata":{"execution":{"iopub.status.busy":"2021-11-16T22:34:22.048269Z","iopub.execute_input":"2021-11-16T22:34:22.048574Z","iopub.status.idle":"2021-11-16T22:34:22.056167Z","shell.execute_reply.started":"2021-11-16T22:34:22.048541Z","shell.execute_reply":"2021-11-16T22:34:22.054608Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"#concat the dataset into a dataframe \n#so that we can see the shape and the info\nfull_data = pd.concat([train_df, test_df, val_df], axis=0, ignore_index=True)","metadata":{"execution":{"iopub.status.busy":"2021-11-16T22:34:25.543874Z","iopub.execute_input":"2021-11-16T22:34:25.544193Z","iopub.status.idle":"2021-11-16T22:34:25.550787Z","shell.execute_reply.started":"2021-11-16T22:34:25.544152Z","shell.execute_reply":"2021-11-16T22:34:25.549785Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"#view the first four rows and the last five rows\nprint(full_data.head())\nprint(full_data.tail())","metadata":{"execution":{"iopub.status.busy":"2021-11-16T22:34:48.768687Z","iopub.execute_input":"2021-11-16T22:34:48.769000Z","iopub.status.idle":"2021-11-16T22:34:48.778781Z","shell.execute_reply.started":"2021-11-16T22:34:48.768969Z","shell.execute_reply":"2021-11-16T22:34:48.777634Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"full_data.shape","metadata":{"execution":{"iopub.status.busy":"2021-11-16T22:34:52.767696Z","iopub.execute_input":"2021-11-16T22:34:52.768336Z","iopub.status.idle":"2021-11-16T22:34:52.775503Z","shell.execute_reply.started":"2021-11-16T22:34:52.768302Z","shell.execute_reply":"2021-11-16T22:34:52.774559Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"#view the full dataset info\nfull_data.info()","metadata":{"execution":{"iopub.status.busy":"2021-11-16T22:34:55.276733Z","iopub.execute_input":"2021-11-16T22:34:55.277052Z","iopub.status.idle":"2021-11-16T22:34:55.292754Z","shell.execute_reply.started":"2021-11-16T22:34:55.277005Z","shell.execute_reply":"2021-11-16T22:34:55.291660Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"#checking if the target is balance \nsns.countplot(full_data[\"target\"])\nplt.title(\"NORMAL/PNOMONİA\")\nplt.show()\nprint(full_data[\"target\"].value_counts())","metadata":{"execution":{"iopub.status.busy":"2021-11-16T22:34:57.748306Z","iopub.execute_input":"2021-11-16T22:34:57.748938Z","iopub.status.idle":"2021-11-16T22:34:57.953098Z","shell.execute_reply.started":"2021-11-16T22:34:57.748904Z","shell.execute_reply":"2021-11-16T22:34:57.952044Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":"**Observation** \n- Clearly, the data seems to be imbalanced in this case. Now in order to balance the distribution of the training examples, we would be using data augmentation procedure. first let's visualize the images to see the X-ray that is Normal and not Normal(Pneumonia).\n","metadata":{}},{"cell_type":"code","source":"#plot the images that is normal and Pneumonia\nplt.figure(figsize=(15,8))\n\nplt.subplot(2,3,1) \nimg = load_img(train_dir + \"/\" + full_data[\"images\"][0])\nplt.imshow(img)\nplt.title(\"PNEUMONIA\", color = \"blue\", size = 14)\nplt.axis(\"off\")\n\n\nplt.subplot(2,3,2) \nimg = load_img(train_dir + \"/\" + full_data[\"images\"][1])\nplt.imshow(img)\nplt.title(\"PNEUMONIA\", color = \"blue\", size = 14)\nplt.axis(\"off\")\n\nplt.subplot(2,3,3) \nimg = load_img(train_dir + \"/\" + full_data[\"images\"][10])\nplt.imshow(img)\nplt.title(\"PNEUMONIA\", color = \"blue\", size = 14)\nplt.axis(\"off\")\n\nplt.subplot(2,3,4) \nimg = load_img(train_dir + \"/\" + full_data[\"images\"][3875])\nplt.imshow(img)\nplt.title(\"NORMAL\", color = \"green\", size = 14)\nplt.axis(\"off\")\n\nplt.subplot(2,3,5) \nimg = load_img(train_dir + \"/\" + full_data[\"images\"][3876])\nplt.imshow(img)\nplt.title(\"NORMAL\", color = \"green\", size = 14)\nplt.axis(\"off\")\n\nplt.subplot(2,3,6) \nimg = load_img(train_dir + \"/\" + full_data[\"images\"][3877])\nplt.imshow(img)\nplt.title(\"NORMAL\", color = \"green\", size = 14)\nplt.axis(\"off\")\n\nplt.suptitle(\"NORMAL or PNEUMONIA\", size = 16, color = \"darkred\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-16T22:35:04.901109Z","iopub.execute_input":"2021-11-16T22:35:04.901907Z","iopub.status.idle":"2021-11-16T22:35:06.526329Z","shell.execute_reply.started":"2021-11-16T22:35:04.901869Z","shell.execute_reply":"2021-11-16T22:35:06.525471Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"markdown","source":"# Data Augmentation\n- Data augmentation is used to increase the size of our data based on the existing data. it acts asa regularizer to help reduce overfitting, especially in this case where we have an imbalanced target.","metadata":{}},{"cell_type":"code","source":"# Fitting the CNN to the images\n# The function ImageDataGenerator augments your image by iterating through image as your CNN is getting ready to process that image\n\ntrain_datagen = ImageDataGenerator(rescale = 1./255,\n                                   shear_range = 0.3,\n                                   brightness_range=(0.9,1),\n                                   zoom_range = 0.3,\n                                   validation_split= 0.1)\n\ntest_datagen = ImageDataGenerator(rescale = 1./255)  #Image normalization.\n\nval_datagen = ImageDataGenerator(rescale = 1./255) #Image normalization.\n\ntraining_generator = train_datagen.flow_from_directory(train_dir,\n                                                       target_size = (64, 64),\n                                                       batch_size = 32,\n                                                       subset = 'training',\n                                                       color_mode='grayscale',\n                                                       class_mode = 'binary')\n\ntest_generator = test_datagen.flow_from_directory(test_dir,\n                                                  target_size=(64, 64),\n                                                  batch_size=32,\n                                                  color_mode='grayscale',\n                                                  class_mode='binary')\n\nval_generator = train_datagen.flow_from_directory(train_dir,\n                                                  target_size = (64, 64),\n                                                  batch_size = 32,\n                                                  class_mode = 'binary',\n                                                  color_mode='grayscale',\n                                                  subset ='validation')","metadata":{"execution":{"iopub.status.busy":"2021-11-17T01:14:30.494650Z","iopub.execute_input":"2021-11-17T01:14:30.494985Z","iopub.status.idle":"2021-11-17T01:14:33.644377Z","shell.execute_reply.started":"2021-11-17T01:14:30.494955Z","shell.execute_reply":"2021-11-17T01:14:33.642954Z"},"trusted":true},"execution_count":116,"outputs":[]},{"cell_type":"code","source":"#define an input shape so that we can use it for modeling\ninput_shape = X_train.shape[1:]\ninput_shape","metadata":{"execution":{"iopub.status.busy":"2021-11-17T01:17:41.337667Z","iopub.execute_input":"2021-11-17T01:17:41.337976Z","iopub.status.idle":"2021-11-17T01:17:41.346527Z","shell.execute_reply.started":"2021-11-17T01:17:41.337944Z","shell.execute_reply":"2021-11-17T01:17:41.345341Z"},"trusted":true},"execution_count":122,"outputs":[]},{"cell_type":"code","source":"#Instantiate sequential and add input layer\nmodel = Sequential()\nmodel.add(Conv2D(32,(3,3),activation = 'relu',padding='same',input_shape = input_shape))\nmodel.add(Conv2D(32,(3,3),activation='relu',padding='same'))\nmodel.add(MaxPooling2D())\n\n#Layers\nmodel.add(Conv2D(32,(3,3),activation='relu',padding='same'))\nmodel.add(Conv2D(32,(3,3),activation='relu',padding='same'))\nmodel.add(MaxPooling2D())\n\n#layers\nmodel.add(Conv2D(64,(3,3),activation='relu',padding='same'))\nmodel.add(Conv2D(64,(3,3),activation='relu',padding='same'))\nmodel.add(MaxPooling2D())\n\n#output\nmodel.add(Flatten())\nmodel.add(Dense(1024, activation='relu'))\nmodel.add(Dropout(0.4))\nmodel.add(Dense(1, activation='sigmoid'))\n\nmodel.compile(loss='binary_crossentropy',\n             optimizer ='adam',\n             metrics=['accuracy'])\n","metadata":{"execution":{"iopub.status.busy":"2021-11-17T01:34:26.242925Z","iopub.execute_input":"2021-11-17T01:34:26.243223Z","iopub.status.idle":"2021-11-17T01:34:26.359632Z","shell.execute_reply.started":"2021-11-17T01:34:26.243190Z","shell.execute_reply":"2021-11-17T01:34:26.358692Z"},"trusted":true},"execution_count":137,"outputs":[]},{"cell_type":"code","source":"#get the model summary\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-11-17T01:34:30.238678Z","iopub.execute_input":"2021-11-17T01:34:30.239006Z","iopub.status.idle":"2021-11-17T01:34:30.255608Z","shell.execute_reply.started":"2021-11-17T01:34:30.238973Z","shell.execute_reply":"2021-11-17T01:34:30.254403Z"},"trusted":true},"execution_count":138,"outputs":[]},{"cell_type":"code","source":"#we are creating a early stopping so that when our \n#model reaches the desired level we can stop it\nfrom tensorflow.keras.callbacks import EarlyStopping\nearly_stopping = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=2)","metadata":{"execution":{"iopub.status.busy":"2021-11-17T01:34:34.846123Z","iopub.execute_input":"2021-11-17T01:34:34.847105Z","iopub.status.idle":"2021-11-17T01:34:34.854168Z","shell.execute_reply.started":"2021-11-17T01:34:34.847067Z","shell.execute_reply":"2021-11-17T01:34:34.852055Z"},"trusted":true},"execution_count":139,"outputs":[]},{"cell_type":"code","source":"#examine the accuracy score and the loss score using the holdout training validation set.\nhistory = model.fit_generator(training_generator,\n                             steps_per_epoch=4695//32,\n                             epochs =20,\n                             validation_data = val_generator,\n                             validation_steps= 521//32,\n                             callbacks=[early_stopping])","metadata":{"execution":{"iopub.status.busy":"2021-11-17T01:34:39.998835Z","iopub.execute_input":"2021-11-17T01:34:39.999858Z","iopub.status.idle":"2021-11-17T01:44:43.716014Z","shell.execute_reply.started":"2021-11-17T01:34:39.999815Z","shell.execute_reply":"2021-11-17T01:44:43.714234Z"},"trusted":true},"execution_count":140,"outputs":[]},{"cell_type":"code","source":"#evaluate the model\nprint('Acuracy of the model is: ',model.evaluate_generator(val_generator)[1]*100,'%')\nprint('Loss of the model is: ', model.evaluate_generator(val_generator)[0])","metadata":{"execution":{"iopub.status.busy":"2021-11-17T02:11:48.853314Z","iopub.execute_input":"2021-11-17T02:11:48.853679Z","iopub.status.idle":"2021-11-17T02:12:00.607262Z","shell.execute_reply.started":"2021-11-17T02:11:48.853608Z","shell.execute_reply":"2021-11-17T02:12:00.606325Z"},"trusted":true},"execution_count":150,"outputs":[]},{"cell_type":"code","source":"history.history.keys()","metadata":{"execution":{"iopub.status.busy":"2021-11-17T02:07:46.224860Z","iopub.execute_input":"2021-11-17T02:07:46.225647Z","iopub.status.idle":"2021-11-17T02:07:46.235378Z","shell.execute_reply.started":"2021-11-17T02:07:46.225607Z","shell.execute_reply":"2021-11-17T02:07:46.233847Z"},"trusted":true},"execution_count":146,"outputs":[]},{"cell_type":"code","source":"#plot the accuracy and loss on a graph to visualize how the model is doing.\nplt.figure()\nplt.plot(history.history[\"loss\"],label = \"Train Loss\")\nplt.plot(history.history[\"val_loss\"],label = \"Validation Loss\")\nplt.legend()\nplt.show()\n\nplt.figure()\nplt.plot(history.history[\"accuracy\"],label = \"Train Accuracy\")\nplt.plot(history.history[\"val_accuracy\"],label = \"Validation Accuracy\")\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-17T02:12:41.372838Z","iopub.execute_input":"2021-11-17T02:12:41.373138Z","iopub.status.idle":"2021-11-17T02:12:41.873503Z","shell.execute_reply.started":"2021-11-17T02:12:41.373107Z","shell.execute_reply":"2021-11-17T02:12:41.872551Z"},"trusted":true},"execution_count":151,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}